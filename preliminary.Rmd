# Preliminaries

I want these notes to serve as an example of how to keep your analyses organized and reproducible.  Analysis projects have many common elements, which include gathering data, cleaning and organizing data, preparing descriptive summaries, testing hypotheses, writing reports, and dissemination.  The end product should be a complete pipeline that takes you from soup to nuts with clear documentation.   While these notes are not perfect, they provide one example of how to prepare a workflow.

These notes are written completely in R. They are organized across several Rmd files (like this one) that are executed in a particular order. For example, the file that reads the data and cleans the data is sourced before the file that produces the descriptive summaries of the data.  

I can reproduce all my analyses and so can you. I put the files for this project (except for the data downloads) in a git repository that you can clone and follow along. Further, I tried to be diligent in using git commits and writing clear comments so you can see how these notes developed; edits I made to the text; code I edited, de-bugged and re-edited; turns I took in my analyses that were dead ends so I didn't pursue them; etc.  This is all part of the regular scientific process.  In the "old days" scientists maintained lab notebooks where they recorded everything they did. A git repository serves the analogous role of an electronic library. It keeps track of everything I did for this project.  You can read the final product (the notes you are currently reading) but you are free to see my thought process, see how I edited these documents, and see the order in which I actually wrote things rather than the order they are presented.  All you have to do is visit the [github site for this project](https://github.com/gonzoum/covid19-analyses).

## Libraries and Setup

```{r setup}
#assumes knitr is installed in R
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=50),tidy=TRUE)
```

I organize in one place all the R packages that are used in these notes so they can be easily installed.

```{r message=F,warning=F,results='hide'}
#be careful in case there are conflicts between these packages
#e.g., select in dplyr is written over by a select function in a different package
#so need to call select from dplyr with dplyr::select
library(bookdown)
library(readr)
library(tidyverse)
library(rvest)
library(magrittr)
library(stringr)
library(tidycensus)
library(ggplot2)
library(gganimate)
library(ggeffects)
library(scales)
library(maps)
library(ggthemes)
library(viridis)
library(ggrepel)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(lme4)
library(nlme)
library(merTools)
library(Hmisc)
library(readxl)
library(rnn)
library(stargazer)
library(texreg)
library(gamm4)
library(splines)
library(mgcv)
library(nlrx)
```

```{asis echo=longform}
For ease of use it would be better to use the pacman package because it also checks if the libraries are installed on your computer (if not, the package automatically downloads them along with all their dependencies).  Finally, pacman initiates the library() call for each library in the list leaving you ready to proceed with the analyses. For illustration, here is the pacman code you would use. This facilitates reproducibility.  
```

```{r eval=F, echo=longform}
#if pacman isn't installed, then install it and issue library(pacman)
if(!("pacman" %in% installed.packages()[,"Package"])) install.packages("pacman")
library(pacman)
#double check all the libraries listed above are listed here too
p_load("bookdown","readr","tidyverse","rvest","magrittr","stringr","tidycensus","ggplot2","gganimate","ggeffects", "scales", 
       "maps","ggthemes","viridis","ggrepel","sjPlot","sjmisc", "sjlabelled","lme4","nlme","merTools","Hmisc","readxl","rnn","stargazer","texreg"
       "gamm4","splines","mgcv","nlrx")
```

```{asis echo=longform}

## Setting variables

When building these files there are some functions that take a long time to complete, like the animations and I don't want to wait each time for the animations to be consructed while I try to debug other aspects of the code.  So here I set cache. Rmarkdown will not run the commands if cache=T but will store the results and reuse them during sequent runs. When I want to have a true new build where everything runs (and can take about 10 minutes) I'll set cache=F.  The cache feature has some capabilities to know when it needs to rerun because a dependency has changed elsewhere in the code.

By putting it here I just have to change the value (T vs F) in one place and elsewhere in the code the cache will be set. This way I don't have to hunt several files for where I need to set cache.
```

```{r echo=longform}
cache <- T
```



```{asis echo=longform}
## Utility functions

Here are some functions I wrote that I will use later. I put them here to improve flow and readability of the key content.

### Multiple Plots {#multiplot}

This function puts multiple ggplots on the same page.  There are now packages that can do this as well, like [patchwork](https://patchwork.data-imaginist.com/), [gridExtra](https://cran.r-project.org/web/packages/egg/vignettes/Ecosystem.html) and [gtable](https://cran.r-project.org/web/packages/gtable/index.html), but I've been using this simple function for years even before such packages existed. I offer this function, which I got off someone's website years ago, as an example of how relatively simple some R functions can be, even when performing complex tasks like arranging multiple plots on a page.  I believe this multiplot() function is now embedded in a [larger package](http://larmarange.github.io/JLutils/reference/multiplot.html).
````

```{r echo=longform}
#Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

```

```{asis echo=longform}

### Caterpillar Plot

Useful plot from this [link](https://stackoverflow.com/questions/13847936/plot-random-effects-from-lmer-lme4-package-using-qqmath-or-dotplot-how-to-mak) that I'll use to plot random effects.
```

```{r echo=longform}
## re = object of class ranef.mer
ggCaterpillar <- function(re, QQ=TRUE, likeDotplot=TRUE) {
    require(ggplot2)
    f <- function(x) {
        pv   <- attr(x, "postVar")
        cols <- 1:(dim(pv)[1])
        se   <- unlist(lapply(cols, function(i) sqrt(pv[i, i, ])))
        ord  <- unlist(lapply(x, order)) + rep((0:(ncol(x) - 1)) * nrow(x), each=nrow(x))
        pDf  <- data.frame(y=unlist(x)[ord],
                           ci=1.96*se[ord],
                           nQQ=rep(qnorm(ppoints(nrow(x))), ncol(x)),
                           ID=factor(rep(rownames(x), ncol(x))[ord], levels=rownames(x)[ord]),
                           ind=gl(ncol(x), nrow(x), labels=names(x)))

        if(QQ) {  ## normal QQ-plot
            p <- ggplot(pDf, aes(nQQ, y))
            p <- p + facet_wrap(~ ind, scales="free")
            p <- p + xlab("Standard normal quantiles") + ylab("Random effect quantiles")
        } else {  ## caterpillar dotplot
            p <- ggplot(pDf, aes(ID, y)) + coord_flip()
            if(likeDotplot) {  ## imitate dotplot() -> same scales for random effects
                p <- p + facet_wrap(~ ind)
            } else {           ## different scales for random effects
                p <- p + facet_grid(ind ~ ., scales="free_y")
            }
            p <- p + xlab("Levels") + ylab("Random effects")
        }

        p <- p + theme(legend.position="none")
        p <- p + geom_hline(yintercept=0)
        p <- p + geom_errorbar(aes(ymin=y-ci, ymax=y+ci), width=0, colour="black")
        p <- p + geom_point(aes(size=1.2), colour="blue") 
        return(p)
    }

    lapply(re, f)
}

```

::: {.infobox .caution data-latex="{caution}"}
**R Notes**

For better reproducibility it is good to use a package like renv that saves the current versions of all your packages used in your pipeline. This way if  a package is updated tomorrow and the new version breaks your code, you at least have the earlier version of the package available locally on your drive to continue running the same code.
:::
